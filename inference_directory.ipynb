{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674b356-8848-4228-892a-79e83f214244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "from natsort import natsorted\n",
    "from dcase24t6.nn.hub import baseline_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b84277-1c2d-4b66-ba7a-92ef06892424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load audio files from a directory\n",
    "def load_audio_files(directory):\n",
    "    audio_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.wav') or f.endswith('.flac')]\n",
    "    audio_files = natsorted(audio_files)\n",
    "    return audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a54c4-11c8-4127-a3bd-53aa2256794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform inference and save results\n",
    "def perform_inference(input_directory):\n",
    "    # Initialize the baseline model\n",
    "    try:\n",
    "        model = baseline_pipeline()\n",
    "        model.eval()\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing model: {e}\") \n",
    "        return\n",
    "    # Load audio files\n",
    "    audio_files = load_audio_files(input_directory)\n",
    "    # Process each audio file\n",
    "    for audio_file in audio_files:\n",
    "        try:\n",
    "            # Use librosa to load audio file and convert to mono channel\n",
    "            data, sr = librosa.load(audio_file, mono=True, sr=None)\n",
    "            data = torch.from_numpy(data).float()\n",
    "            \n",
    "            # Check audio dimention and add one if only has one.\n",
    "            if len(data.shape) == 1:\n",
    "                data = data.unsqueeze(0)  # Add a batch dimention\n",
    "            \n",
    "            item = {\"audio\": data, \"sr\": sr}\n",
    "            \n",
    "            # Perform inference\n",
    "            candidate = model(item)\n",
    "            candidates = candidate['candidates']\n",
    "            \n",
    "            if candidates: \n",
    "                candidate_str = candidates[0]\n",
    "            else:\n",
    "                candidate_str = \"\"\n",
    "        \n",
    "            # print(f\"File: {audio_file}, Candidate: {candidates}\")\n",
    "            file_name = audio_file.replace('/workspace/final_60/','')\n",
    "            file_name = file_name.replace('.wav','')\n",
    "            file_name = file_name.replace('.flac','')\n",
    "            print(f'{file_name}:\\nCandidate: {candidate_str}')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {audio_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506aa026-0bde-4e22-a9ea-d74a53eaad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input directories\n",
    "input_directory = '/path/to/files/'  # Replace with the path to your input directory\n",
    "\n",
    "# Perform inference on the audio files\n",
    "perform_inference(input_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cfd335-6a4a-473b-8038-07d9c9e83343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
